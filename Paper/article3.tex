%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Stylish Article
% LaTeX Template
% Version 2.2 (2020-10-22)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Mathias Legrand (legrand.mathias@gmail.com) 
% With extensive modifications by:
% Vel (vel@latextemplates.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[fleqn,10pt]{SelfArx} % Document font size and equations flushed left
\usepackage{float}
\usepackage[english]{babel} % Specify a different language here - english by default
\usepackage[numbers]{natbib}
\usepackage{url}
\usepackage{lipsum} % Required to insert dummy text. To be removed otherwise
\usepackage{tabularx}
\usepackage{tcolorbox}
\usepackage{siunitx}
\tcbuselibrary{xparse}
\sisetup{
    group-digits=true,
    group-separator={\,},
}
%----------------------------------------------------------------------------------------
%	COLUMNS
%----------------------------------------------------------------------------------------

\setlength{\columnsep}{0.55cm} % Distance between the two columns of text
\setlength{\fboxrule}{0.75pt} % Width of the border around the abstract

%----------------------------------------------------------------------------------------
%	COLORS
%----------------------------------------------------------------------------------------

\definecolor{color1}{RGB}{0,0,90} % Color of the article title and sections
\definecolor{color2}{RGB}{0,20,20} % Color of the boxes behind the abstract and headings

%----------------------------------------------------------------------------------------
%	HYPERLINKS
%----------------------------------------------------------------------------------------

\usepackage{hyperref} % Required for hyperlinks

\hypersetup{
	hidelinks,
	colorlinks,
	breaklinks=true,
	urlcolor=color2,
	citecolor=color1,
	linkcolor=color1,
	bookmarksopen=false,
	pdftitle={Title},
	pdfauthor={Author},
}

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

\JournalInfo{Data Scientist Nanodegree} % Journal information
\Archive{Capstone Project} % Additional notes (e.g. copyright, DOI, review/research article)

\PaperTitle{Short Term Stock Price Prediction with Machine Learning} % Article title

\Authors{Lucas Breinlinger\textsuperscript{1}} % Authors
\affiliation{\textsuperscript{1}\textit{Contact: lucasbr@me.com}} % Author affiliation


\Keywords{} % Keywords - if you don't want any simply remove all the text between the curly brackets
\newcommand{\keywordname}{Keywords} % Defines the keywords heading name

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{Accurately predicting stock prices is a highly sought after mastery. In recent developments Long Short Term Memory, a type of recurrent neural network, have proven to be highly promising in achieving better predictions.
todo: add 3-10 sentences blabla + result + methodology}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Output the title and abstract box

\tableofcontents % Output the contents section

\thispagestyle{empty} % Removes page numbering from the first page

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section{Project Definition} % The \section*{} command stops section numbering

The accurate forecast of stock prices, traded on an exchange, is inarguably one of the most challeging topics in the field of asset pricing. The stock market is described as a unpredictable, dynamic and non-linear construct. Predicting the prices of its stocks is a ambitious undertaking and depends on many variables including but not limited to global economy, company's metrics and local and global political situation. 

Historically there are two main prediction metods. The fundamental analysis which is a qualitative analysis of the company is interested in finding the true value of a stock and compare it to the actual traded value. The evaluator utilizes several performance criterias e.g. the P/E ratio in order to truely assess the underlying stock. Secondly, the technical analysis, which is solely based on the past price of the stock e.g. in form of closing or opening prices as time-series. Its rather a short term predicing using factors like the Moving Average (MA) or the Exponential Moving Average (EMA). Its basic assumption is that every significant information about the stock is already considered in the stock price.

The fast computational development has led to the point that Machine learning techniques have a significant application in financial problem. The use of artificial neural networks have found more and its way into the field of stock price prediction. Here a recurrent neural network (RNN) has found very proven, more precisely the Long Short Term Memory (LSTM). Its advantage being
able to process entire sequences of data rather than only one single data point. It has proven to be very practial with time series data such our historical stock prices. 

In this project, I create an application which is going to predict the \textbf{closing price} of any given stock for which it is trained on. For the sake of convenience this report only considers the stock price prediction of the \textbf{Apple} Inc. (\textit{\$AAPL}) stock.

A train-test cycle is used to test the accuracy of the prediction. The root mean squared error (\ref{eq.rmse}) is used to measure the accuracy of the mode:
\begin{equation}
RMSE = \sqrt{\dfrac{\Sigma_{i}(\hat{y}_i-y_i)}{N}} 
\label{eq.rmse}
\end{equation}
where $\hat{y}_i$ is the prediction of the $i-th$ stock price $y_i$ and $N$ is the total number of predicted stock prices.


%------------------------------------------------

\section{Data Analysis}

\begin{table*}[hbt]
	\caption{First lines of \textit{Apple Inc.} stock prices dataset}
	\centering
\begin{tabular}{lllrrrr S[table-auto-round,table-format=9.0] rr}
\toprule
Ticker &       Name &       Date &  Open &  High &   Low &  Close &       {Volume} &  Dividends &  Stock Splits \\
\midrule
  AAPL & Apple Inc. & 2012-07-19 & 18.77 & 18.90 & 18.61 &  18.87 & 436861600.00 &       0 &          0 \\
  AAPL & Apple Inc. & 2012-07-20 & 18.83 & 18.87 & 18.54 &  18.56 & 397471200.00 &       0 &          0 \\
  AAPL & Apple Inc. & 2012-07-23 & 18.25 & 18.61 & 18.05 &  18.54 & 487975600.00 &       0 &          0 \\
  AAPL & Apple Inc. & 2012-07-24 & 18.65 & 18.72 & 18.38 &  18.45 & 565132400.00 &       0 &          0 \\
  AAPL & Apple Inc. & 2012-07-25 & 17.64 & 17.84 & 17.51 &  17.66 & 877312800.00 &       0 &          0 \\
\bottomrule
\end{tabular}
	\label{tab:df.head}
\end{table*}

\begin{table*}[hbt]
	\caption{Statistics of the Apple stock prices. Which represent our used features}
	\centering
\begin{tabular}{lS[table-auto-round,table-format=9.1] S[table-auto-round,table-format=9.1] S[table-auto-round,table-format=9.1] S[table-auto-round,table-format=9.1]S[table-auto-round,scientific-notation = engineering, table-format=-1.1e-1]  S[table-auto-round,table-format=9.0]}
\toprule
{} &         {Open} &         {High} &          {Low}&        {Close}              \\
\midrule
count &  2514.000000 &  2514.000000 &  2514.000000 &  2514.000000  \\
mean  &    54.976304 &    55.586809 &    54.385991 &    55.010195 \\
std   &    45.998891 &    46.593796 &    45.425948 &    46.036470  \\
min   &    12.090742 &    12.453181 &    12.001301 &    12.170523  \\
25\%   &    22.846671 &    23.103172 &    22.672594 &    22.848148 \\
50\%   &    36.503730 &    36.712400 &    36.239020 &    36.499804  \\
75\%   &    66.667990 &    68.501637 &    65.989975 &    67.521479  \\
max   &   182.630005 &   182.940002 &   179.119995 &   182.009995  \\
\bottomrule
\end{tabular}
	\label{tab:df.statistrics}
\end{table*}


The dataset was collected with the help of \tcboxverb{yfinance} python plugin. In my case it is replacing the not working Yahoo Finance API. The collected dataframe contains
\begin{itemize}[noitemsep] % [noitemsep] removes whitespace between the items for a compact look
	\item \num{1108837} rows
	\item $10$ columns
	\item price information for $457$ unique stocks
	\item Data of the last 10 years (including 17/07/2022)
\end{itemize} and was collected on the 18/07/2022. I use a list of 457 randomly selected stock tickers to generate the dataset. 

The structure and the first 5 lines of the table filtered for \textit{Apple Inc.} are displayed in table \ref{tab:df.head}. For each day and each stock (denoted by its ticker (\textit{Ticker}) and company name (\textit{Name}) the dataset contains the price of the stock in dollar 
when opening the market (\textit{Open}), closing the market (\textit{Close}). Furthermore there the days lowest (\textit{Low}) and highest 
intra-day price (\textit{High} is available, as well as the daily traded volume (\textit{Volume}).


Looking at the \textit{Apple Inc.} stock there are 2514 columns regarding the apple stock with a minimum closing price of $12.17$ and a maximum closing price of $182.01$. There are no missing values (see table \ref{tab:df.statistrics}) in the dataset, and the date and value columns are correctly set as a datetime respectively float columns. In table \ref{tab:df.statistrics} the statistics of the distinctive variables are shown.

\begin{figure}[ht]\centering
	\includegraphics[width=\linewidth]{closing}
	\caption{Closing price of the \textit{Apple Inc.} in the last 10 years.}
	\label{fig:results}
\end{figure}

In figure \ref{fig:results} the highly volatile closing price of the stock is shown for its last 10 years. In recent years the stocke prices have incresead roughly sevenfold. 




%------------------------------------------------

\section{Methodology}

\begin{figure*}[tb]\centering % Using \begin{figure*} makes the figure take up the entire width of the page
	\includegraphics[scale=0.3]{LSTM}
	\caption{The reccurent cell of a LSTM network \cite{LSTM}.}
	\label{fig:lstm.network}
\end{figure*}

Here, I am using a Recurrent Neural Network for the stock price prediction. More specifically a Long Short Term Memory Network is used to build the model. These networks are capable of learning long-term dependencies and are commonly used for handling and forecasting time-series data. In figure \ref{fig:lstm.network} a recurrent cell of a LSTM network is shown. Each cell consists of three gates, an input gate, an output gate and a forget gate. 

Those cells are linked together to a chain, where each cell looks at the input gate at the previous hidden state $h_{t-1}$,the current input $x_t$, and the previous cell state $c_{t-1}$. The forget cell is the first part where $h_{t-1}$ and $x_t$ are passed through the sigmoid activation function and pointwise multiplied with the cell state $c_{t-1}$. The input gates combines a sigmoid and tanh layer, here it is decided which parts are going to be updated. Multiplying both layers determines which information is used to update the cell state by pointwise adding it the the output of the forget gate, resulting in the final $c_t$.
In the output gate the same input ($h_{t-1}$ and $x_t$) is passed through a sigmoid function and finally multiplied with the current cell state $c_t$, yielding the final output the hidden state $h_t$.

In order for the LSTM to work properly the stock closing prices have to be normalized. This will help our model to converge faster and be more stable. Furthermore when using the scaler on more than one input features with different scales all features will contribute equally to the fitting and there will be no bias due to a different scaling. I am using the MinMaxScaler (\ref{eq.minmax}) of sci-kit learn.
\begin{equation}
x_{i,scaled}=\dfrac{x_i-min(x)}{max(x)-min(x)}
\label{eq.minmax}
\end{equation}

Here, I am trying to predict future stock prices $y_t$ (target) with the help of the previous $n$ stock prices. For example I am predicting the stock price from day 11 using day 1 to 10 as my features, for day 12, using day 2-11 and so on. In order to do this I defined a splitting function which generates me a data sample consisting of $n$ samples (the previous stock prices) and the target value $n + 1$. $n$ is denoting the size of my window which I am using to predict the prices. This function is applied to my previously scaled stock prices. 

Finally I split this data set in a training and a test set, since we are dealing with a time-series we cannot randomly select the samples, rather I split the sample at some point. In my experiment I am using $80\%$ as a training set and the remaining $20\%$ as my test set. Using the predicted stock price $\hat{y}_i$ and the real stock price $y_t$ of the test set the RMSE can be easily calculated using eq. \ref{eq.rmse}.

\begin{table*}[hbt]
	\caption{Overview of the model parameters.}
	\centering
\begin{tabular}{lcccccc}
\hline
Model & LSTM 1 & LSTM 2 & Dense 1 & Dense 2 & Epoch & $n$ \\ 
\hline 
simple & 10 & - & 1 & - & 1 & 30 \\ 

refined 1 & 10 & 10 & 25 & 1 & 1 & 30 \\ 

refined 2 & 50 & 50 & 25 & 1 & 1 & 30 \\ 

refined 3 & 150 & 150 & 25 & 1 & 5 & 30 \\
\end{tabular}

\label{table.model} 
\end{table*}

The first \textbf{simple model} I build, consisted of a single LSTM layer with 10 neurons and a dense Layer with 1 neuron. The dense layer is needed to get the dimensionality of the output of the LSTM $h_t$ back to a 1D output. I am using the previous thirty close prices ($n=30$) as my input $x_t$.

My refined model is a deeper neural network, since the relations between stock prices are quite complicated. Thus, I added an additional LSTM layer and a second dense layer with 25 neurons. The refined model is run with different parameters, the first run is 10 neurons for both LSTM layers, the next run is 50 neurons for both layers and in my last model I am using 150 neurons and 5 epochs . All the time $n$ is kept at $30$ days.

In table \ref{table.model} the model parameters are shown in an overview.


\section{Results}
As expected the $RMSE$ for the refined model is smaller than for the simple model. Furthermore the refined model 3 with 150 neurons per LSTM and 5 epochs also performed better than the refined model with less neurons. For comparison see the values for all four models in table \ref{tab:rsme}.
\begin{table}[H]
	\caption{The resulting $RMSE$ of the four models.}
	\centering
	\begin{tabular}{cr}
	\hline 
	Model & $RMSE$ \\ 
	\hline 
	simple & 37.83 \\ 
	refined 1 & 28.34 \\ 
	refined 2 & 9.59 \\ 
	refined 3 & 3.74 \\ 
	\hline 
	\end{tabular} 
	\label{tab:rsme}
\end{table}
The poor performance of the simple model can also seen in figure \ref{fig:simple} and \ref{fig:simple_zoom}. The prediction follows loosely the real price, however is much higher than the real price.
\begin{figure}[ht]\centering
	\includegraphics[width=\linewidth]{simple_model}
	\caption{The prediction close price of the simple model versus the real close price.}
	\label{fig:simple}
\end{figure}

\begin{figure}[ht]\centering
	\includegraphics[width=\linewidth]{simple_model_zoom}
	\caption{The prediction close price for the last 60 days of the simple model versus the real close price.}
	\label{fig:simple_zoom}
\end{figure}

\section{Conclusion}





%------------------------------------------------



%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------

\phantomsection
\addcontentsline{toc}{section}{References} % Adds this section to the table of contents
\bibliographystyle{unsrt}
\bibliography{sample.bib}

%----------------------------------------------------------------------------------------

\end{document}